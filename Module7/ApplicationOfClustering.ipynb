{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Cluster Models\n",
    "\n",
    "In this lab you will apply K-means and agglomerative to clustering to finding structure in the automotive data set. Finding meaningful clusters in such a complex data set will prove challenging. The challenge is two-fold. First, the optimal number of clusters must be determined. Then the clusters must be interpreted in some useful manner. These challenges are typical of unsupervised learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset\n",
    "\n",
    "Before you start building and evaluating cluster models, the dataset must be prepared. First, execute the code in the cell below to load the packages required to run the rest of this notebook. \n",
    "\n",
    "\n",
    "> **Note:** If you are running in Azure Notebooks, make sure that you run the code in the `setup.ipynb` notebook at the start of you session to ensure your environment is correctly configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(gridExtra)\n",
    "library(MASS)\n",
    "library(gridExtra)\n",
    "library(cluster)\n",
    "library(caret)\n",
    "library(repr)\n",
    "library(dplyr)\n",
    "\n",
    "options(repr.plot.width=4, repr.plot.height=4) # Set the initial plot area dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below loads a prepared version of the autos dataset which has the the following preprocessing:\n",
    "1. Clean missing values.\n",
    "2. Aggregate categories of certain categorical variables. \n",
    "\n",
    "However, for this case, some additional processing is required:\n",
    "1. Select columns of interest to eliminate columns known to not be useful as features.\n",
    "2. Encode the categorical features as dummy variables.\n",
    "3. Log transform certain numeric columns. \n",
    "4. Z-score normalize the numeric features. \n",
    "5. Near zero variance features are removed.\n",
    "\n",
    "Execute the code in the cell below to import and select columns of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the 'Auto_Prices_Preped.csv' and assign it to \"auto_prices\"\n",
    "\n",
    "\n",
    "# make a subset of auto_prices, selecting only 'make', 'fuel.type', 'aspiration', 'num.of.doors', 'body.style'\n",
    "#                             'drive.wheels', 'wheel.base', 'length', 'width', 'height',\n",
    "#                             'curb.weight', 'num.of.cylinders', 'engine.size', 'bore', \n",
    "#                             'stroke', 'compression.ratio', 'horsepower', 'peak.rpm', \n",
    "#                             'city.mpg', 'highway.mpg', and 'log_price'\n",
    "# assign this selection to auto_prices\n",
    "\n",
    "\n",
    "# inspect the names of auto_prices\n",
    "\n",
    "\n",
    "# inspect the dimensions of auto_prices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset has 21 columns (dimensions) for a small number of cases, 195. The small number of rows compared to the number of features adds to the challenge of this problem. \n",
    "\n",
    "Next, execute the code below to encode the categorical variables as dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy variables out of the categorical variables, using highway.mpg\n",
    "dummies = dummyVars(highway.mpg ~ ., data = auto_prices)\n",
    "auto_dummies = data.frame(predict(dummies, newdata = auto_prices))\n",
    "\n",
    "# inspect the names of auto_dummies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to logarithmically transform certain numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = c('wheel.base', 'curb.weight', 'engine.size', 'bore', 'stroke', 'horsepower', \n",
    "             'city.mpg', 'log_price')\n",
    "\n",
    "# use lapply() on the numeric columns (num_cols) of auto_dummies, and get the log of these values. \n",
    "# Hint: you have done this before, but instead of log you used scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to Z Score normalize the numeric variables using the `preProcess` function from the Caret package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = c('wheel.base', 'length', 'width', 'height', 'curb.weight', 'engine.size',\n",
    "             'bore', 'stroke', 'compression.ratio', 'horsepower', 'peak.rpm', 'city.mpg',\n",
    "             'log_price')\n",
    "\n",
    "preProcValues <- preProcess(auto_dummies[,num_cols], method = c(\"center\", \"scale\"))\n",
    "\n",
    "auto_dummies[,num_cols] = predict(preProcValues, auto_dummies[,num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, execute the code in the cell below to identify near zero variance variables using the `nearZeroVar` function from the Caret package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "near_zero = nearZeroVar(auto_dummies, freqCut = 95/5, uniqueCut = 10, saveMetrics = TRUE)\n",
    "near_zero[(near_zero$zeroVar == TRUE) | (near_zero$nzv == TRUE), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below removes columns with near zero variance. The `select` verb from the R dplyr package along with the `starts_with` function is used. Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_dummies = select(auto_dummies, -starts_with(\"make\"), -starts_with(\"num.of.doors\"), \n",
    "                     -drive.wheels.4wd, -num.of.cylinders.eight_twelve)\n",
    "\n",
    "# inspect the names of auto_dummies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply K-means clustering\n",
    "\n",
    "With the data prepared, you will now create and evaluate a series of K-means clustering models applied to the automotive data set. The code in the cell below computes a k=2 k-means cluster model. The cluster assignments are appended to the data frame. Execute this code.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed to 4455\n",
    "\n",
    "# create a k-means cluster model \"kmeans_2\" with the function kmeans()\n",
    "# inspect the function kmeans() with ?kmeans in R studio\n",
    "# use auto_dummies as data\n",
    "# set the number of centers to 2\n",
    "\n",
    "\n",
    "# append the assigned cluster from your model to the auto_prices\n",
    "auto_prices[,'assignment'] = kmeans_2$cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the code in the cell below plots four views of the cluster assignments. With high dimensional data many views are possible. However, given limits of perception it is often best to select a few meaningful views. In this case 4 numeric columns and 1 categorical variable are displayed, for a total of 5 of 25 possible dimensions. The function in the cell below displays 4 projections of the cluster assignments. Fuel type is shown by shape. Legend (scales) are displayed only for cluster assignment to reduce clutter. Execute this code to display the cluster assignments for the K=2 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auto_cluster = function(auto_dummies){\n",
    "    options(repr.plot.width=8, repr.plot.height=4.5)\n",
    "    grid.arrange(ggplot(auto_dummies, aes_string('city.mpg','log_price')) +\n",
    "                    geom_point(aes(color = factor(assignment), shape = factor(fuel.type), alpha = 0.2)) +\n",
    "                    scale_shape(guide = FALSE) + scale_alpha(guide = FALSE),\n",
    "                 ggplot(auto_dummies, aes_string('curb.weight','log_price')) +\n",
    "                    geom_point(aes(color = factor(assignment), shape = factor(fuel.type), alpha = 0.2)) +\n",
    "                    scale_shape(guide = FALSE) + scale_alpha(guide = FALSE),\n",
    "                 ggplot(auto_dummies, aes_string('curb.weight','city.mpg')) +\n",
    "                    geom_point(aes(color = factor(assignment), shape = factor(fuel.type), alpha = 0.2)) +\n",
    "                    scale_shape(guide = FALSE) + scale_alpha(guide = FALSE),\n",
    "                 ggplot(auto_dummies, aes_string('horsepower','log_price')) +\n",
    "                    geom_point(aes(color = factor(assignment), shape = factor(fuel.type), alpha = 0.2)) +\n",
    "                    scale_shape(guide = FALSE) + scale_alpha(guide = FALSE),\n",
    "                 ncol = 2)\n",
    "}\n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K=2 clustering model has divided the data between high price, low fuel efficiency, high weight and high horsepower autos and ones that have the opposite characteristics. While this clustering is interesting, it can hardly be considered surprising. \n",
    "\n",
    "Next, execute the code in the cell below to compute and display the cluster assignments for the K=3 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed to 4665\n",
    "\n",
    "# create a k-means cluster model \"kmeans_3\" with the function kmeans()\n",
    "# inspect the function kmeans() with ?kmeans in R studio\n",
    "# use auto_dummies as data\n",
    "# set the number of centers to 3\n",
    "\n",
    "\n",
    "# append the assigned cluster kmeans_3$cluster from your model to auto_prices[,'assignment'] \n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic divisions of the dataset between the clusters is similar to the K=2 model case. Diesel autos are shown with circular markers and are largely separated into a cluster. \n",
    "\n",
    "Execute the code in the cell below to compute and display the cluster assignments for the K=4 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed to 475\n",
    "\n",
    "# create a k-means cluster model \"kmeans_4\" with the function kmeans()\n",
    "# inspect the function kmeans() with ?kmeans in R studio\n",
    "# use auto_dummies as data\n",
    "# set the number of centers to 4\n",
    "\n",
    "\n",
    "# append the assigned cluster kmeans_4$cluster from your model to auto_prices[,'assignment'] \n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a bit more overlap between the clusters for this model. Some additional interesting structure is starting to emerge. Primary divisions of these clusters are by price, weight, fuel efficiency, horsepower and fuel type. All of the diesel autos are in two clusters, one with high cost, weight and horse power, and one for lower cost, weight and horse power. \n",
    "\n",
    "Execute the code in the cell below to compute and display the cluster assignments for a K=5 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed to 475\n",
    "\n",
    "# create a k-means cluster model \"kmeans_5\" with the function kmeans()\n",
    "# inspect the function kmeans() with ?kmeans in R studio\n",
    "# use auto_dummies as data\n",
    "# set the number of centers to 5\n",
    "\n",
    "\n",
    "# append the assigned cluster from your model to auto_prices[,'assignment'] \n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of these clusters is rather complex. The general pattern is similar to the K=4 model, but with finer grained division of the cases and more overlap between the clusters. \n",
    "\n",
    "Finally, execute the code in the cell below to compute and display the class assignments for the K=6 model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set the seed to 475\n",
    "\n",
    "# create a k-means cluster model \"kmeans_6\" with the function kmeans()\n",
    "# inspect the function kmeans() with ?kmeans in R studio\n",
    "# use auto_dummies as data\n",
    "# set the number of centers to 6\n",
    "\n",
    "\n",
    "# append the assigned cluster from your model to auto_prices[,'assignment'] \n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of these clusters follows the general pattern of the K=4 and K=5 models. The difference being that there is a finer grained divisions between the clusters and yet more overlap.\n",
    "\n",
    "While these visualizations are interesting, it is hard to select a best model based on just this evidence. To establish a quantitative basis for model selection, you will now compute and compare the within cluster sum of squares (WCSS), between cluster sum of squares (BCSS) and silhouette coefficient (SC) metrics. Execute the code in the cell below and examine the results.\n",
    "\n",
    "Then, answer **Question 1** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = dist(auto_dummies)\n",
    "plot_clust_metrics = function(kmeans_2, kmeans_3, kmeans_4, kmeans_5, kmeans_6){\n",
    "    options(repr.plot.width=7, repr.plot.height=6) # Set the plot area dimensions\n",
    "    \n",
    "    ## Create a data frame with the sum of the WCSS and BCSS and approximate ave SC as columns\n",
    "    kmeans_metrics = data.frame(model = c('k=2', 'k=3', 'k=4', 'k=5', 'k=6'), \n",
    "                            WCSS = c(sum(kmeans_2$withinss), sum(kmeans_3$withinss), sum(kmeans_4$withinss),\n",
    "                                      sum(kmeans_5$withinss), sum(kmeans_6$withinss)),\n",
    "                            BCSS = c(sum(kmeans_2$betweenss), sum(kmeans_3$betweenss), sum(kmeans_4$betweenss),\n",
    "                                      sum(kmeans_5$betweenss), sum(kmeans_6$betweenss)),\n",
    "                            SC = c(mean(silhouette(kmeans_2$cluster, dist_mat)[,3]),\n",
    "                                   mean(silhouette(kmeans_3$cluster, dist_mat)[,3]),\n",
    "                                   mean(silhouette(kmeans_4$cluster, dist_mat)[,3]),\n",
    "                                   mean(silhouette(kmeans_5$cluster, dist_mat)[,3]),\n",
    "                                   mean(silhouette(kmeans_6$cluster, dist_mat)[,3])))\n",
    "    ## Create side by side plots of WCSS and BCSS vs. the model\n",
    "    p_wcss = ggplot(kmeans_metrics, aes(model, WCSS)) + geom_point(size = 3) +\n",
    "                ggtitle('Within cluster sum of squares \\n vs. model')\n",
    "    p_bcss = ggplot(kmeans_metrics, aes(model, BCSS)) + geom_point(size = 3) +\n",
    "                ggtitle('Between cluster sum of squares \\n vs. model')\n",
    "    p_sc = ggplot(kmeans_metrics, aes(model, SC)) + geom_point(size = 3) +\n",
    "                ggtitle('Average silhouette coefficient \\n vs. model')\n",
    "    grid.arrange(p_wcss, p_bcss, p_sc, ncol = 2)\n",
    "    }\n",
    "\n",
    "plot_clust_metrics(kmeans_2, kmeans_3, kmeans_4, kmeans_5, kmeans_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WCSS decreases and BCSS increases with increasing numbers of clusters. The range of WCSS and BCSS values is relatively narrow. However, the SC is highest for the k=2 and k=3 models. The other models have noticeably lower SC. However, all these SC values are fairly low. Overall, it appears that the k=3 model might be the best overall compromise between these metrics. The greater level of detail with greater numbers of clusters will be important for some applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply agglomerative clustering\n",
    "\n",
    "Having tried the K-means clustering mode with various numbers of clusters, you will now try agglomerative clustering models. You will compare these models using both visualization and the SC metric.  \n",
    "\n",
    "The code in the cell below computes a 2 cluster agglomerative model and displays the cluster assignments. Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed to 7799\n",
    "\n",
    "# create a hierarchical cluster analysis \"a_clusts\" with the function hclust()\n",
    "# inspect the function hclust() with ?hclust in R studio\n",
    "# use dist_mat as data\n",
    "# set the method to 'average'\n",
    "\n",
    "\n",
    "# use the function cutree() to cut a tree into groups of data, in this case into 2 groups\n",
    "# inspect the function cutree() with ?cutree in R studio\n",
    "agglomerative_2 = cutree(a_clusts, k = 2)\n",
    "\n",
    "# append the agglomerative_2 to auto_prices[,'assignment'] \n",
    "auto_prices[,'assignment'] = agglomerative_2\n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the above plots and compare them to the cluster assignments for the K=2 K-means model. Whereas the K-means model created an approximately even split of the dataset, the agglomerative clustering model has placed the majority of points in one cluster. \n",
    "\n",
    "Next, execute the code in the cell below to compute and display the assignments for the 3 cluster agglomerative model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the function cutree() to cut a_clusts into 3 clusters (k=3) and assign it to \"agglomerative_3\"\n",
    "# inspect the function cutree() with ?cutree in R studio\n",
    "\n",
    "\n",
    "# append agglomerative_3 to auto_prices[,'assignment'] \n",
    "\n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these plots and compare them to the 2 cluster model. It appears the 3 cluster model has split the larger cluster, but with considerable overlap in these views. \n",
    "\n",
    "Execute the code in the cell below to compute and display the cluster assignments for the 4 cluster agglomerative model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the function cutree() to cut a_clusts into 4 clusters (k=4) and assign it to \"agglomerative_4\"\n",
    "# inspect the function cutree() with ?cutree in R studio\n",
    "\n",
    "\n",
    "# append agglomerative_4 to auto_prices[,'assignment'] \n",
    "\n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these cluster assignments to the 3 cluster model. Notice that low weight, low horsepower and low cost autos have been split into two clusters. \n",
    "\n",
    "Execute the code in the cell below to compute and display the cluster assignments for a 5 cluster model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the function cutree() to cut a_clusts into 5 clusters (k=5) and assign it to \"agglomerative_5\"\n",
    "# inspect the function cutree() with ?cutree in R studio\n",
    "\n",
    "\n",
    "# append agglomerative_5 to auto_prices[,'assignment'] \n",
    "\n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cases are now split into 5 fairly distinct groups with minimal overlap. Compare each of the four views above to see how the clusters divide these cases.  \n",
    "\n",
    "Finally, execute the code in the cell below to compute and display the assignments for the 6 cluster agglomerative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the function cutree() to cut a_clusts into 6 clusters (k=6) and assign it to \"agglomerative_6\"\n",
    "# inspect the function cutree() with ?cutree in R studio\n",
    "\n",
    "\n",
    "# append agglomerative_6 to auto_prices[,'assignment'] \n",
    "\n",
    "\n",
    "# plot auto_prices with plot_auto_cluster()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results appear similar to the 5 cluster model. As should be expected, there is a slightly finer division of some of the cases. \n",
    "\n",
    "Finally, execute the code in the cell below to compute and display the SC for the agglomerative clustering models. \n",
    "\n",
    "Then, answer **Question 2** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=4, repr.plot.height=4) # Set the plot area dimensions\n",
    "\n",
    "SC_metrics = data.frame(model = c('2 cluster', '3 cluster', '4 cluster',\n",
    "                                 '5 cluster', '6 cluster'),\n",
    "                        SC = c(mean(silhouette(agglomerative_2, dist_mat)[,3]),\n",
    "                                mean(silhouette(agglomerative_3, dist_mat)[,3]),\n",
    "                                mean(silhouette(agglomerative_4, dist_mat)[,3]),\n",
    "                                mean(silhouette(agglomerative_5, dist_mat)[,3]),\n",
    "                                mean(silhouette(agglomerative_6, dist_mat)[,3])))\n",
    "\n",
    "ggplot(SC_metrics, aes(model, SC)) + geom_point(size = 3) +\n",
    "                ggtitle('Average silhouette coefficient \\n vs. model') +\n",
    "                theme(axis.text.x = element_text(angle = 90, hjust = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SC values are in a narrow range. The 2 cluster model has the highest SC. However, the 5 and 6 cluster models exhibit reasonable divisions of the cases and have reasonable SC values. Therefore these models are preferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you have computed, evaluated and compared K-means and agglomerative clustering models with 2, 3, 4, 5 and 6 clusters applied to the automotive dataset. As is often the case with unsupervised learning, it has proven difficult to compare models. It is also challenging to determine the most interesting aspects of data structure discovered by the clustering process. \n",
    "\n",
    "Specifically, your analysis discovered:\n",
    "1. The k=3 model appears to be the best compromise between the metrics for the of the k-means models. \n",
    "2. The 5 or 6 cluster agglomerative models appear the be the best of those tried. As with the K-means model, some interesting structure was revealed, but the SC values were relatively low. \n",
    "\n",
    "Cluster analysis of the automotive data can be extended in a number of ways, including:\n",
    "1. Use larger numbers of clusters to determine if finer groupings reveal structure. \n",
    "2. For agglomerative clustering model try other linkage functions and distance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
