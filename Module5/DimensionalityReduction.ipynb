{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction with principal components\n",
    "\n",
    "**Principal component analysis**, or **PCA**, is an alternative to regularization and straight-forward feature elimination. PCA is particularly useful for problems with very large numbers of features compared to the number of training cases. For example, when faced with a problem with many thousands of features and perhaps a few thousand cases, PCA can be a good choice to **reduce the dimensionality** of the feature space.  \n",
    "\n",
    "PCA is one of a family of transformation methods that reduce dimensionality. PCA is the focus here, since it is the most widely used of these methods. \n",
    "\n",
    "The basic idea of PCA is rather simple: Find a linear transformation of the feature space which **projects the majority of the variance** onto a few orthogonal dimensions in the transformed space. The PCA transformation maps the data values to a new coordinate system defined by the principal components. Assuming the highest variance directions, or **components**, are the most informative, low variance components can be eliminated from the space with little loss of information. \n",
    "\n",
    "The projection along which the greatest variance occurs is called the **first principal component**. The next projection, orthogonal to the first, with the greatest variance is called the **second principal component**. Subsequent components are all mutually orthogonal with decreasing variance along the projected direction.  \n",
    "\n",
    "Widely used PCA algorithms compute the components sequentially, starting with the first principal component. This means that it is computationally efficient to compute the first several components from a very large number of features. Thus, PCA can make problems with very large numbers of features computationally tractable. \n",
    "\n",
    "****\n",
    "**Note:** It may help your understanding to realize that principal components are a scaled version of the **eigenvectors** of the feature matrix. The scale for each dimensions is given by the **eigenvalues**. The eigenvalues are the fraction of the variance explained by the components. \n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example\n",
    "\n",
    "To cement the concepts of PCA you will now work through a simple example. This example is restricted to 2-d data so that the results are easy to visualize. \n",
    "\n",
    "As a first step, execute the code in cell below to load the packages required for the rest of this notebook.\n",
    "\n",
    "> **Note:** If you are running in Azure Notebooks, make sure that you run the code in the `setup.ipynb` notebook at the start of you session to ensure your environment is correctly configured. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Attaching package: 'MASS'\n",
      "\n",
      "The following object is masked from 'package:dplyr':\n",
      "\n",
      "    select\n",
      "\n",
      "Loading required package: gplots\n",
      "\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n",
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "Attaching package: 'pROC'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "library(ggplot2)\n",
    "library(repr)\n",
    "library(dplyr)\n",
    "library(caret)\n",
    "library(MASS)\n",
    "library(ROCR)\n",
    "library(pROC)\n",
    "\n",
    "options(repr.plot.width=4, repr.plot.height=4) # Set the initial plot area dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below simulates data from a bivariate Normal distribution. The distribution is deliberately centered on $\\{ 0,0 \\}$ and with unit variance on each dimension. There is considerable covariance between the two dimensions leading to a covariance matrix:\n",
    "\n",
    "$$cov(X) =  \\begin{bmatrix}\n",
    "  1.0 & 0.6 \\\\\n",
    "  0.6 & 1.0\n",
    " \\end{bmatrix}$$\n",
    "\n",
    "Given the covariance matrix 100 draws from this distribution are computed using the `mvrnorm` function from the R MASS package. Execute this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 100   2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x</th><th scope=col>y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-1.0289674 </td><td>-1.44872226</td></tr>\n",
       "\t<tr><td> 0.5476797 </td><td>-0.47912514</td></tr>\n",
       "\t<tr><td>-1.1761978 </td><td>-0.18875203</td></tr>\n",
       "\t<tr><td> 0.3192489 </td><td> 0.06053589</td></tr>\n",
       "\t<tr><td> 1.3990650 </td><td> 1.15101479</td></tr>\n",
       "\t<tr><td> 1.0575449 </td><td> 0.27422109</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " x & y\\\\\n",
       "\\hline\n",
       "\t -1.0289674  & -1.44872226\\\\\n",
       "\t  0.5476797  & -0.47912514\\\\\n",
       "\t -1.1761978  & -0.18875203\\\\\n",
       "\t  0.3192489  &  0.06053589\\\\\n",
       "\t  1.3990650  &  1.15101479\\\\\n",
       "\t  1.0575449  &  0.27422109\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x | y | \n",
       "|---|---|---|---|---|---|\n",
       "| -1.0289674  | -1.44872226 | \n",
       "|  0.5476797  | -0.47912514 | \n",
       "| -1.1761978  | -0.18875203 | \n",
       "|  0.3192489  |  0.06053589 | \n",
       "|  1.3990650  |  1.15101479 | \n",
       "|  1.0575449  |  0.27422109 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x          y          \n",
       "1 -1.0289674 -1.44872226\n",
       "2  0.5476797 -0.47912514\n",
       "3 -1.1761978 -0.18875203\n",
       "4  0.3192489  0.06053589\n",
       "5  1.3990650  1.15101479\n",
       "6  1.0575449  0.27422109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(124)\n",
    "cov = matrix(c(1.0, 0.6, 0.6, 1.0), nrow =2, ncol = 2)\n",
    "mean = c(0.0, 0.0)\n",
    "\n",
    "sample = data.frame(mvrnorm(n = 100, mu = mean, Sigma = cov))\n",
    "names(sample) = c('x','y')\n",
    "print(dim(sample))\n",
    "head(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a feel for this data, execute the code in the cell below to display a plot and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAM1BMVEUAAAAzMzNNTU1oaGh8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\ntzC2ylIAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(sample, aes(x,y)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the data have a roughly elliptical pattern. The correlation between the two dimensions is also visible. \n",
    "\n",
    "With the simulated data set created, it is time to compute the PCA model. The code in the cell below computes the principle component model using the R `prcomp` function. This function contains a list with multiple elements including the eigenvalues. The eigenvalues can be scaled to compute the variance explained:\n",
    "\n",
    "$$VE(X) = \\frac{Var_{X-component}(X)}{Var_{X-total}(X)}$$\n",
    "\n",
    "Notice that by construction:\n",
    "\n",
    "$$VE(X) = \\sum_{i=1}^N VE_i(X) = 1.0$$\n",
    "\n",
    "In other words, the sum of the variance explained for each component must add to the total variance or 1.0 for standardized data. \n",
    "\n",
    "Execute this code and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard deviations:\n",
       "[1] 1.1197401 0.5688762\n",
       "\n",
       "Rotation:\n",
       "        PC1        PC2\n",
       "x 0.6595985 -0.7516182\n",
       "y 0.7516182  0.6595985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_mod = prcomp(sample)\n",
    "pca_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the standard deviation of the first component is several times larger than for the second component. This is exactly the desired result indicating the first principal component explains the majority of the variance of the sample data. Mathematically the components are the eigenvectors and the standard deviations are  the eigenvalues of the data covariance matrix. \n",
    "\n",
    "The code in the cell below computes and prints the scaled magnitude of the components. These scaled components must add to 1.0. Execute this code:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.794844456022692</li>\n",
       "\t<li>0.205155543977308</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.794844456022692\n",
       "\\item 0.205155543977308\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.794844456022692\n",
       "2. 0.205155543977308\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.7948445 0.2051555"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sdev_scaled = pca_mod$sdev**2/sum(pca_mod$sdev**2)\n",
    "sdev_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components are scaled by element wise multiplication with percent variance explained. Execute this code and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t2 obs. of  2 variables:\n",
      " $ PC1: num  0.524 0.597\n",
      " $ PC2: num  -0.154 0.135\n"
     ]
    }
   ],
   "source": [
    "scaled_pca = data.frame(matrix(c(0,0,0,0), nrow = 2, ncol = 2))\n",
    "for(i in 1:2){\n",
    "    scaled_pca[i,] = pca_mod$rotation[i,] * sdev_scaled\n",
    "}\n",
    "names(scaled_pca) = c('PC1','PC2')\n",
    "str(scaled_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two component vectors have their origins at $[ 0,0 \\}$, and are quite different magnitude, and are pointing in different directions. To better understand how the projections of the components relate to the data, execute the code to plot the data along with the principal components. Execute this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nAJ48ADx5AHjyAPDkAeDJA8CTB4Anj/8DU3NijauNQQkAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Find the slopes\n",
    "s1 = data.frame(x = c(0.0, scaled_pca$PC1[1]), y = c(0.0, scaled_pca$PC1[2]))\n",
    "s2 = data.frame(x = c(0.0, scaled_pca$PC2[1]), y = c(0.0, scaled_pca$PC2[2]))\n",
    "\n",
    "## Plot the data with the PCs\n",
    "ggplot(sample, aes(x,y)) + geom_point() +\n",
    "        geom_line(data = s1, aes(x,y), color = 'red', size = 1) +\n",
    "        geom_line(data = s2, aes(x,y), color = 'red', size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the the first principal component (the long red line) is along the direction of greatest variance of the data. This is as expected. The short red line is along the direction of the second principal component. The lengths of these lines are the variance in the directions of the projection. \n",
    "\n",
    "The ultimate goal of PCA is to transform data to a coordinate system with the highest variance directions along the axes. The `transform` function in the cell below computes the projections of the data onto the new coordinate frames using matrix multiplication. Execute this code to apply the transform and plot the result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAM1BMVEUAAAAzMzNNTU1oaGh8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\n8OAB4MEDwIMHgAcPAA8e/wNXOoER0yExkAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_transform = function(df, pca, ncomps){\n",
    "    data.frame(as.matrix(df) %*% as.matrix(pca)[,1:ncomps])\n",
    "}\n",
    "\n",
    "trans_sample = pca_transform(sample, scaled_pca, 2)\n",
    "names(trans_sample) = c('x', 'y')\n",
    "ggplot(trans_sample, aes(x,y)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the scale along these two coordinates are quite different. The first principal component is along the horizontal axis. The range of values on this direction is in the range of about $\\{ -2.5,2.5 \\}$. The range of values on the vertical axis or second principal component are only about $\\{ -0.2, 0.3 \\}$. It is clear that most of the variance is along the direction of the fist principal component. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features and Labels\n",
    "\n",
    "Keeping the foregoing simple example in mind, it is time to apply PCA to some real data. \n",
    "\n",
    "The code in the cell below loads the dataset which has the following preprocessing:\n",
    "1. Cleaning missing values.\n",
    "2. Aggregating categories of certain categorical variables. \n",
    "\n",
    "Execute the code in the cell below to load the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>21</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 21\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 21\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1000 obs. of  21 variables:\n",
      " $ checking_account_status : Factor w/ 4 levels \"< 0 DM\",\"> 200 DM or salary assignment\",..: 1 3 4 1 1 4 4 3 4 3 ...\n",
      " $ loan_duration_mo        : int  6 48 12 42 24 36 24 36 12 30 ...\n",
      " $ credit_history          : Factor w/ 5 levels \"all loans at bank paid\",..: 2 3 2 3 5 3 3 3 3 2 ...\n",
      " $ purpose                 : Factor w/ 10 levels \"business\",\"car (new)\",..: 8 8 5 6 2 5 6 3 8 2 ...\n",
      " $ loan_amount             : int  1169 5951 2096 7882 4870 9055 2835 6948 3059 5234 ...\n",
      " $ savings_account_balance : Factor w/ 5 levels \"< 100 DM\",\">= 1000 DM\",..: 5 1 1 1 1 5 4 1 2 1 ...\n",
      " $ time_employed_yrs       : Factor w/ 5 levels \"< 1 year\",\">= 7 years\",..: 2 3 4 4 3 3 2 3 4 5 ...\n",
      " $ payment_pcnt_income     : int  4 2 2 2 3 2 3 2 2 4 ...\n",
      " $ gender_status           : Factor w/ 4 levels \"female-divorced/separated/married\",..: 4 1 4 4 4 4 4 4 2 3 ...\n",
      " $ other_signators         : Factor w/ 3 levels \"co-applicant\",..: 3 3 3 2 3 3 3 3 3 3 ...\n",
      " $ time_in_residence       : int  4 2 3 4 4 4 4 2 4 2 ...\n",
      " $ property                : Factor w/ 4 levels \"building society savings/life insurance\",..: 3 3 3 1 4 4 1 2 3 2 ...\n",
      " $ age_yrs                 : int  67 22 49 45 53 35 53 35 61 28 ...\n",
      " $ other_credit_outstanding: Factor w/ 3 levels \"bank\",\"none\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ home_ownership          : Factor w/ 3 levels \"for free\",\"own\",..: 2 2 2 1 1 1 2 3 2 2 ...\n",
      " $ number_loans            : int  2 1 1 1 2 1 1 1 1 2 ...\n",
      " $ job_category            : Factor w/ 4 levels \"highly skilled\",..: 2 2 4 2 2 4 2 1 4 1 ...\n",
      " $ dependents              : int  1 1 2 2 2 2 1 1 1 1 ...\n",
      " $ telephone               : Factor w/ 2 levels \"none\",\"yes\": 2 1 1 1 1 2 1 2 1 1 ...\n",
      " $ foreign_worker          : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ bad_credit              : Factor w/ 2 levels \"bad\",\"good\": 2 1 2 2 1 2 2 2 2 1 ...\n"
     ]
    }
   ],
   "source": [
    "credit = read.csv('German_Credit_Preped.csv', header = TRUE)\n",
    "credit[,'Customer_ID'] = NULL\n",
    "credit$bad_credit <- ifelse(credit$bad_credit == 1, 'bad', 'good')\n",
    "credit$bad_credit <- factor(credit$bad_credit, levels = c('bad', 'good'))\n",
    "dim(credit)\n",
    "str(credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20 features in this data set. \n",
    "\n",
    "The prcomp function can only work with numeric matrices. Therefore, the categorical features are dummy variable encoded. Executed the code in the cell below to compute the encoding for the dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = dummyVars(bad_credit ~ ., data = credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below to split the data set into test and training subsets and dummy variable encode the categorical features. The Caret `createDataPartion` function is used  to randomly split the dataset. The `perdict` method dummy variable encodes the categorical features. Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$lvls):\n",
      "\"variable 'bad_credit' is not a factor\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>700</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 700\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 700\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 700  61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$lvls):\n",
      "\"variable 'bad_credit' is not a factor\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>300</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 300\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 300\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 300  61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>checking_account_status.&lt; 0 DM</th><th scope=col>checking_account_status.&gt; 200 DM or salary assignment</th><th scope=col>checking_account_status.0 - 200 DM</th><th scope=col>checking_account_status.none</th><th scope=col>loan_duration_mo</th><th scope=col>credit_history.all loans at bank paid</th><th scope=col>credit_history.critical account - other non-bank loans</th><th scope=col>credit_history.current loans paid</th><th scope=col>credit_history.no credit - paid</th><th scope=col>credit_history.past payment delays</th><th scope=col>...</th><th scope=col>number_loans</th><th scope=col>job_category.highly skilled</th><th scope=col>job_category.skilled</th><th scope=col>job_category.unemployed-unskilled-non-resident</th><th scope=col>job_category.unskilled-resident</th><th scope=col>dependents</th><th scope=col>telephone.none</th><th scope=col>telephone.yes</th><th scope=col>foreign_worker.no</th><th scope=col>foreign_worker.yes</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td> 6 </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>2  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>12 </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>2  </td><td>1  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>42 </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>2  </td><td>1  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>24 </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>...</td><td>2  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>2  </td><td>1  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>24 </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>1  </td><td>1  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>36 </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>0  </td><td>...</td><td>1  </td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td><td>0  </td><td>1  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "  & checking\\_account\\_status.< 0 DM & checking\\_account\\_status.> 200 DM or salary assignment & checking\\_account\\_status.0 - 200 DM & checking\\_account\\_status.none & loan\\_duration\\_mo & credit\\_history.all loans at bank paid & credit\\_history.critical account - other non-bank loans & credit\\_history.current loans paid & credit\\_history.no credit - paid & credit\\_history.past payment delays & ... & number\\_loans & job\\_category.highly skilled & job\\_category.skilled & job\\_category.unemployed-unskilled-non-resident & job\\_category.unskilled-resident & dependents & telephone.none & telephone.yes & foreign\\_worker.no & foreign\\_worker.yes\\\\\n",
       "\\hline\n",
       "\t1 & 1   & 0   & 0   & 0   &  6  & 0   & 1   & 0   & 0   & 0   & ... & 2   & 0   & 1   & 0   & 0   & 1   & 0   & 1   & 0   & 1  \\\\\n",
       "\t3 & 0   & 0   & 0   & 1   & 12  & 0   & 1   & 0   & 0   & 0   & ... & 1   & 0   & 0   & 0   & 1   & 2   & 1   & 0   & 0   & 1  \\\\\n",
       "\t4 & 1   & 0   & 0   & 0   & 42  & 0   & 0   & 1   & 0   & 0   & ... & 1   & 0   & 1   & 0   & 0   & 2   & 1   & 0   & 0   & 1  \\\\\n",
       "\t5 & 1   & 0   & 0   & 0   & 24  & 0   & 0   & 0   & 0   & 1   & ... & 2   & 0   & 1   & 0   & 0   & 2   & 1   & 0   & 0   & 1  \\\\\n",
       "\t7 & 0   & 0   & 0   & 1   & 24  & 0   & 0   & 1   & 0   & 0   & ... & 1   & 0   & 1   & 0   & 0   & 1   & 1   & 0   & 0   & 1  \\\\\n",
       "\t8 & 0   & 0   & 1   & 0   & 36  & 0   & 0   & 1   & 0   & 0   & ... & 1   & 1   & 0   & 0   & 0   & 1   & 0   & 1   & 0   & 1  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | checking_account_status.< 0 DM | checking_account_status.> 200 DM or salary assignment | checking_account_status.0 - 200 DM | checking_account_status.none | loan_duration_mo | credit_history.all loans at bank paid | credit_history.critical account - other non-bank loans | credit_history.current loans paid | credit_history.no credit - paid | credit_history.past payment delays | ... | number_loans | job_category.highly skilled | job_category.skilled | job_category.unemployed-unskilled-non-resident | job_category.unskilled-resident | dependents | telephone.none | telephone.yes | foreign_worker.no | foreign_worker.yes | \n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 1   | 0   | 0   | 0   |  6  | 0   | 1   | 0   | 0   | 0   | ... | 2   | 0   | 1   | 0   | 0   | 1   | 0   | 1   | 0   | 1   | \n",
       "| 3 | 0   | 0   | 0   | 1   | 12  | 0   | 1   | 0   | 0   | 0   | ... | 1   | 0   | 0   | 0   | 1   | 2   | 1   | 0   | 0   | 1   | \n",
       "| 4 | 1   | 0   | 0   | 0   | 42  | 0   | 0   | 1   | 0   | 0   | ... | 1   | 0   | 1   | 0   | 0   | 2   | 1   | 0   | 0   | 1   | \n",
       "| 5 | 1   | 0   | 0   | 0   | 24  | 0   | 0   | 0   | 0   | 1   | ... | 2   | 0   | 1   | 0   | 0   | 2   | 1   | 0   | 0   | 1   | \n",
       "| 7 | 0   | 0   | 0   | 1   | 24  | 0   | 0   | 1   | 0   | 0   | ... | 1   | 0   | 1   | 0   | 0   | 1   | 1   | 0   | 0   | 1   | \n",
       "| 8 | 0   | 0   | 1   | 0   | 36  | 0   | 0   | 1   | 0   | 0   | ... | 1   | 1   | 0   | 0   | 0   | 1   | 0   | 1   | 0   | 1   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  checking_account_status.< 0 DM\n",
       "1 1                             \n",
       "3 0                             \n",
       "4 1                             \n",
       "5 1                             \n",
       "7 0                             \n",
       "8 0                             \n",
       "  checking_account_status.> 200 DM or salary assignment\n",
       "1 0                                                    \n",
       "3 0                                                    \n",
       "4 0                                                    \n",
       "5 0                                                    \n",
       "7 0                                                    \n",
       "8 0                                                    \n",
       "  checking_account_status.0 - 200 DM checking_account_status.none\n",
       "1 0                                  0                           \n",
       "3 0                                  1                           \n",
       "4 0                                  0                           \n",
       "5 0                                  0                           \n",
       "7 0                                  1                           \n",
       "8 1                                  0                           \n",
       "  loan_duration_mo credit_history.all loans at bank paid\n",
       "1  6               0                                    \n",
       "3 12               0                                    \n",
       "4 42               0                                    \n",
       "5 24               0                                    \n",
       "7 24               0                                    \n",
       "8 36               0                                    \n",
       "  credit_history.critical account - other non-bank loans\n",
       "1 1                                                     \n",
       "3 1                                                     \n",
       "4 0                                                     \n",
       "5 0                                                     \n",
       "7 0                                                     \n",
       "8 0                                                     \n",
       "  credit_history.current loans paid credit_history.no credit - paid\n",
       "1 0                                 0                              \n",
       "3 0                                 0                              \n",
       "4 1                                 0                              \n",
       "5 0                                 0                              \n",
       "7 1                                 0                              \n",
       "8 1                                 0                              \n",
       "  credit_history.past payment delays ... number_loans\n",
       "1 0                                  ... 2           \n",
       "3 0                                  ... 1           \n",
       "4 0                                  ... 1           \n",
       "5 1                                  ... 2           \n",
       "7 0                                  ... 1           \n",
       "8 0                                  ... 1           \n",
       "  job_category.highly skilled job_category.skilled\n",
       "1 0                           1                   \n",
       "3 0                           0                   \n",
       "4 0                           1                   \n",
       "5 0                           1                   \n",
       "7 0                           1                   \n",
       "8 1                           0                   \n",
       "  job_category.unemployed-unskilled-non-resident\n",
       "1 0                                             \n",
       "3 0                                             \n",
       "4 0                                             \n",
       "5 0                                             \n",
       "7 0                                             \n",
       "8 0                                             \n",
       "  job_category.unskilled-resident dependents telephone.none telephone.yes\n",
       "1 0                               1          0              1            \n",
       "3 1                               2          1              0            \n",
       "4 0                               2          1              0            \n",
       "5 0                               2          1              0            \n",
       "7 0                               1          1              0            \n",
       "8 0                               1          0              1            \n",
       "  foreign_worker.no foreign_worker.yes\n",
       "1 0                 1                 \n",
       "3 0                 1                 \n",
       "4 0                 1                 \n",
       "5 0                 1                 \n",
       "7 0                 1                 \n",
       "8 0                 1                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1955)\n",
    "## Randomly sample cases to create independent training and test data\n",
    "partition = createDataPartition(credit[,'bad_credit'], times = 1, p = 0.7, list = FALSE)\n",
    "training = credit[partition,] # Create the training feature sample\n",
    "training_label = credit[partition, 'bad_credit'] # Subset training labels\n",
    "training = predict(dummies, newdata = training) # transform categorical to dummy vars\n",
    "dim(training)\n",
    "test = credit[-partition,] # Create the test sample\n",
    "test_label = credit[-partition, 'bad_credit'] # Subset training labels\n",
    "test = predict(dummies, newdata = test) # transform categorical to dummy vars\n",
    "dim(test)\n",
    "head(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preforming PCA all features must be zero mean and unit variance. Failure to do so will result in biased computation of the components and scales. The `preProcess` function from Caret is used to compute scaling of the training data. The same scaling is applied to the test data. Execute the code in the cell below to scale the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>loan_duration_mo</th><th scope=col>loan_amount</th><th scope=col>payment_pcnt_income</th><th scope=col>age_yrs</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>-1.2111310 </td><td>-0.7137211 </td><td> 0.91818241</td><td> 2.6286850 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>-0.7100721 </td><td>-0.3883552 </td><td>-0.88723244</td><td> 1.0922267 </td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 1.7952226 </td><td> 1.6424615 </td><td>-0.88723244</td><td> 0.7507916 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td> 0.2920458 </td><td> 0.5852856 </td><td> 0.01547498</td><td> 1.4336619 </td></tr>\n",
       "\t<tr><th scope=row>7</th><td> 0.2920458 </td><td>-0.1289751 </td><td> 0.01547498</td><td> 1.4336619 </td></tr>\n",
       "\t<tr><th scope=row>8</th><td> 1.2941637 </td><td> 1.3146387 </td><td>-0.88723244</td><td>-0.1027964 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & loan\\_duration\\_mo & loan\\_amount & payment\\_pcnt\\_income & age\\_yrs\\\\\n",
       "\\hline\n",
       "\t1 & -1.2111310  & -0.7137211  &  0.91818241 &  2.6286850 \\\\\n",
       "\t3 & -0.7100721  & -0.3883552  & -0.88723244 &  1.0922267 \\\\\n",
       "\t4 &  1.7952226  &  1.6424615  & -0.88723244 &  0.7507916 \\\\\n",
       "\t5 &  0.2920458  &  0.5852856  &  0.01547498 &  1.4336619 \\\\\n",
       "\t7 &  0.2920458  & -0.1289751  &  0.01547498 &  1.4336619 \\\\\n",
       "\t8 &  1.2941637  &  1.3146387  & -0.88723244 & -0.1027964 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | loan_duration_mo | loan_amount | payment_pcnt_income | age_yrs | \n",
       "|---|---|---|---|---|---|\n",
       "| 1 | -1.2111310  | -0.7137211  |  0.91818241 |  2.6286850  | \n",
       "| 3 | -0.7100721  | -0.3883552  | -0.88723244 |  1.0922267  | \n",
       "| 4 |  1.7952226  |  1.6424615  | -0.88723244 |  0.7507916  | \n",
       "| 5 |  0.2920458  |  0.5852856  |  0.01547498 |  1.4336619  | \n",
       "| 7 |  0.2920458  | -0.1289751  |  0.01547498 |  1.4336619  | \n",
       "| 8 |  1.2941637  |  1.3146387  | -0.88723244 | -0.1027964  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  loan_duration_mo loan_amount payment_pcnt_income age_yrs   \n",
       "1 -1.2111310       -0.7137211   0.91818241          2.6286850\n",
       "3 -0.7100721       -0.3883552  -0.88723244          1.0922267\n",
       "4  1.7952226        1.6424615  -0.88723244          0.7507916\n",
       "5  0.2920458        0.5852856   0.01547498          1.4336619\n",
       "7  0.2920458       -0.1289751   0.01547498          1.4336619\n",
       "8  1.2941637        1.3146387  -0.88723244         -0.1027964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_cols = c('loan_duration_mo', 'loan_amount', 'payment_pcnt_income', 'age_yrs')\n",
    "preProcValues <- preProcess(training[,num_cols], method = c(\"center\", \"scale\"))\n",
    "\n",
    "training[,num_cols] = predict(preProcValues, training[,num_cols])\n",
    "test[,num_cols] = predict(preProcValues, test[,num_cols])\n",
    "head(training[,num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute principal components\n",
    "\n",
    "The code in the cell below computes the principal components for the training feature subset. Execute this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_credit = prcomp(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to print the variance explained for each component and the sum of the variance explained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.149730944157874</li>\n",
       "\t<li>0.123636588967734</li>\n",
       "\t<li>0.0865736367434875</li>\n",
       "\t<li>0.074309827697869</li>\n",
       "\t<li>0.0465452393801124</li>\n",
       "\t<li>0.0396904247725725</li>\n",
       "\t<li>0.0337693029734763</li>\n",
       "\t<li>0.0308166719017535</li>\n",
       "\t<li>0.0279956542428432</li>\n",
       "\t<li>0.02767094223441</li>\n",
       "\t<li>0.0247342481835602</li>\n",
       "\t<li>0.0238701648799721</li>\n",
       "\t<li>0.0217907302816068</li>\n",
       "\t<li>0.0213108378916881</li>\n",
       "\t<li>0.0192839827359195</li>\n",
       "\t<li>0.0186205643525818</li>\n",
       "\t<li>0.0173327216894376</li>\n",
       "\t<li>0.0163808712859274</li>\n",
       "\t<li>0.0150424179272427</li>\n",
       "\t<li>0.0147575571095382</li>\n",
       "\t<li>0.0130472466827854</li>\n",
       "\t<li>0.012038260394915</li>\n",
       "\t<li>0.0115221204871724</li>\n",
       "\t<li>0.0110326643359129</li>\n",
       "\t<li>0.0102666229509055</li>\n",
       "\t<li>0.00932812699182411</li>\n",
       "\t<li>0.00907392172858775</li>\n",
       "\t<li>0.00869824951450154</li>\n",
       "\t<li>0.00805077139439395</li>\n",
       "\t<li>0.00734563046334151</li>\n",
       "\t<li>0.00663152457220292</li>\n",
       "\t<li>0.00609713061202495</li>\n",
       "\t<li>0.00587401788867891</li>\n",
       "\t<li>0.00549861212609673</li>\n",
       "\t<li>0.00508175472742823</li>\n",
       "\t<li>0.00468580477298417</li>\n",
       "\t<li>0.00434796269371465</li>\n",
       "\t<li>0.00429032017899004</li>\n",
       "\t<li>0.00411920118379735</li>\n",
       "\t<li>0.00375374581557801</li>\n",
       "\t<li>0.00321654867588973</li>\n",
       "\t<li>0.00284613046711423</li>\n",
       "\t<li>0.00252060460727528</li>\n",
       "\t<li>0.00223302812261362</li>\n",
       "\t<li>0.00159458301607329</li>\n",
       "\t<li>0.00118642926146686</li>\n",
       "\t<li>0.000910710854076942</li>\n",
       "\t<li>0.000844946070047402</li>\n",
       "\t<li>3.1943076604877e-32</li>\n",
       "\t<li>2.40708712096236e-33</li>\n",
       "\t<li>2.08468404630495e-33</li>\n",
       "\t<li>1.13249718949511e-33</li>\n",
       "\t<li>9.89343900294532e-34</li>\n",
       "\t<li>9.10577194396536e-34</li>\n",
       "\t<li>6.11078520834379e-34</li>\n",
       "\t<li>6.11078520834379e-34</li>\n",
       "\t<li>6.11078520834379e-34</li>\n",
       "\t<li>6.11078520834379e-34</li>\n",
       "\t<li>6.11078520834379e-34</li>\n",
       "\t<li>1.94397118368239e-34</li>\n",
       "\t<li>1.31692651965475e-34</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.149730944157874\n",
       "\\item 0.123636588967734\n",
       "\\item 0.0865736367434875\n",
       "\\item 0.074309827697869\n",
       "\\item 0.0465452393801124\n",
       "\\item 0.0396904247725725\n",
       "\\item 0.0337693029734763\n",
       "\\item 0.0308166719017535\n",
       "\\item 0.0279956542428432\n",
       "\\item 0.02767094223441\n",
       "\\item 0.0247342481835602\n",
       "\\item 0.0238701648799721\n",
       "\\item 0.0217907302816068\n",
       "\\item 0.0213108378916881\n",
       "\\item 0.0192839827359195\n",
       "\\item 0.0186205643525818\n",
       "\\item 0.0173327216894376\n",
       "\\item 0.0163808712859274\n",
       "\\item 0.0150424179272427\n",
       "\\item 0.0147575571095382\n",
       "\\item 0.0130472466827854\n",
       "\\item 0.012038260394915\n",
       "\\item 0.0115221204871724\n",
       "\\item 0.0110326643359129\n",
       "\\item 0.0102666229509055\n",
       "\\item 0.00932812699182411\n",
       "\\item 0.00907392172858775\n",
       "\\item 0.00869824951450154\n",
       "\\item 0.00805077139439395\n",
       "\\item 0.00734563046334151\n",
       "\\item 0.00663152457220292\n",
       "\\item 0.00609713061202495\n",
       "\\item 0.00587401788867891\n",
       "\\item 0.00549861212609673\n",
       "\\item 0.00508175472742823\n",
       "\\item 0.00468580477298417\n",
       "\\item 0.00434796269371465\n",
       "\\item 0.00429032017899004\n",
       "\\item 0.00411920118379735\n",
       "\\item 0.00375374581557801\n",
       "\\item 0.00321654867588973\n",
       "\\item 0.00284613046711423\n",
       "\\item 0.00252060460727528\n",
       "\\item 0.00223302812261362\n",
       "\\item 0.00159458301607329\n",
       "\\item 0.00118642926146686\n",
       "\\item 0.000910710854076942\n",
       "\\item 0.000844946070047402\n",
       "\\item 3.1943076604877e-32\n",
       "\\item 2.40708712096236e-33\n",
       "\\item 2.08468404630495e-33\n",
       "\\item 1.13249718949511e-33\n",
       "\\item 9.89343900294532e-34\n",
       "\\item 9.10577194396536e-34\n",
       "\\item 6.11078520834379e-34\n",
       "\\item 6.11078520834379e-34\n",
       "\\item 6.11078520834379e-34\n",
       "\\item 6.11078520834379e-34\n",
       "\\item 6.11078520834379e-34\n",
       "\\item 1.94397118368239e-34\n",
       "\\item 1.31692651965475e-34\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.149730944157874\n",
       "2. 0.123636588967734\n",
       "3. 0.0865736367434875\n",
       "4. 0.074309827697869\n",
       "5. 0.0465452393801124\n",
       "6. 0.0396904247725725\n",
       "7. 0.0337693029734763\n",
       "8. 0.0308166719017535\n",
       "9. 0.0279956542428432\n",
       "10. 0.02767094223441\n",
       "11. 0.0247342481835602\n",
       "12. 0.0238701648799721\n",
       "13. 0.0217907302816068\n",
       "14. 0.0213108378916881\n",
       "15. 0.0192839827359195\n",
       "16. 0.0186205643525818\n",
       "17. 0.0173327216894376\n",
       "18. 0.0163808712859274\n",
       "19. 0.0150424179272427\n",
       "20. 0.0147575571095382\n",
       "21. 0.0130472466827854\n",
       "22. 0.012038260394915\n",
       "23. 0.0115221204871724\n",
       "24. 0.0110326643359129\n",
       "25. 0.0102666229509055\n",
       "26. 0.00932812699182411\n",
       "27. 0.00907392172858775\n",
       "28. 0.00869824951450154\n",
       "29. 0.00805077139439395\n",
       "30. 0.00734563046334151\n",
       "31. 0.00663152457220292\n",
       "32. 0.00609713061202495\n",
       "33. 0.00587401788867891\n",
       "34. 0.00549861212609673\n",
       "35. 0.00508175472742823\n",
       "36. 0.00468580477298417\n",
       "37. 0.00434796269371465\n",
       "38. 0.00429032017899004\n",
       "39. 0.00411920118379735\n",
       "40. 0.00375374581557801\n",
       "41. 0.00321654867588973\n",
       "42. 0.00284613046711423\n",
       "43. 0.00252060460727528\n",
       "44. 0.00223302812261362\n",
       "45. 0.00159458301607329\n",
       "46. 0.00118642926146686\n",
       "47. 0.000910710854076942\n",
       "48. 0.000844946070047402\n",
       "49. 3.1943076604877e-32\n",
       "50. 2.40708712096236e-33\n",
       "51. 2.08468404630495e-33\n",
       "52. 1.13249718949511e-33\n",
       "53. 9.89343900294532e-34\n",
       "54. 9.10577194396536e-34\n",
       "55. 6.11078520834379e-34\n",
       "56. 6.11078520834379e-34\n",
       "57. 6.11078520834379e-34\n",
       "58. 6.11078520834379e-34\n",
       "59. 6.11078520834379e-34\n",
       "60. 1.94397118368239e-34\n",
       "61. 1.31692651965475e-34\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 1.497309e-01 1.236366e-01 8.657364e-02 7.430983e-02 4.654524e-02\n",
       " [6] 3.969042e-02 3.376930e-02 3.081667e-02 2.799565e-02 2.767094e-02\n",
       "[11] 2.473425e-02 2.387016e-02 2.179073e-02 2.131084e-02 1.928398e-02\n",
       "[16] 1.862056e-02 1.733272e-02 1.638087e-02 1.504242e-02 1.475756e-02\n",
       "[21] 1.304725e-02 1.203826e-02 1.152212e-02 1.103266e-02 1.026662e-02\n",
       "[26] 9.328127e-03 9.073922e-03 8.698250e-03 8.050771e-03 7.345630e-03\n",
       "[31] 6.631525e-03 6.097131e-03 5.874018e-03 5.498612e-03 5.081755e-03\n",
       "[36] 4.685805e-03 4.347963e-03 4.290320e-03 4.119201e-03 3.753746e-03\n",
       "[41] 3.216549e-03 2.846130e-03 2.520605e-03 2.233028e-03 1.594583e-03\n",
       "[46] 1.186429e-03 9.107109e-04 8.449461e-04 3.194308e-32 2.407087e-33\n",
       "[51] 2.084684e-33 1.132497e-33 9.893439e-34 9.105772e-34 6.110785e-34\n",
       "[56] 6.110785e-34 6.110785e-34 6.110785e-34 6.110785e-34 1.943971e-34\n",
       "[61] 1.316927e-34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var_exp = pca_credit$sdev**2/sum(pca_credit$sdev**2)\n",
    "var_exp\n",
    "sum(var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are a bit abstract. However, you can see that the variance ratios are in descending order and that the sum is 1.0. \n",
    "\n",
    "Execute the code in the cell below to create a plot of the explained variance vs. the component:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAOVBMVEUAAAAAAP8zMzNNTU1o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\nABPX/yb2cVjcOP00AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scree = function(pca_mod){\n",
    "    ## Plot as variance explained\n",
    "    df = data.frame(x = 1:length(var_exp), y = var_exp)\n",
    "    ggplot(df, aes(x,y)) + geom_line(size = 1, color = 'blue') +\n",
    "    xlab('Component number') + ylab('Variance explained') +\n",
    "    ggtitle('Scree plot of variance explained vs. \\n Principal Component')\n",
    "}\n",
    "\n",
    "plot_scree(pca_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This curve is often referred to as a **scree plot**. Notice that the explained variance decreases rapidly until the 10th component and then slowly, thereafter. The first few components explain a large fraction of the variance and therefore contain much of the explanatory information in the data. The components with small explained variance are unlikely to contain much explanatory information. Often the inflection point or 'knee' in the scree curve is used to choose the number of components selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to create a PCA model with a reduced number of components. The code in the cell below trains and fits a PCA model with 10 components, and then transforms the features using that model. Execute this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"In prcomp.default(training, rank = 10) :\n",
      " extra argument 'rank' will be disregarded\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>61</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 61\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 61\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 61 61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>checking_account_status.&lt; 0 DM</dt>\n",
       "\t\t<dd>0.00418242624022571</dd>\n",
       "\t<dt>checking_account_status.&gt; 200 DM or salary assignment</dt>\n",
       "\t\t<dd>-0.0170404247032728</dd>\n",
       "\t<dt>checking_account_status.0 - 200 DM</dt>\n",
       "\t\t<dd>0.0130986240491562</dd>\n",
       "\t<dt>checking_account_status.none</dt>\n",
       "\t\t<dd>-0.000240625586109156</dd>\n",
       "\t<dt>loan_duration_mo</dt>\n",
       "\t\t<dd>0.591263628398861</dd>\n",
       "\t<dt>credit_history.all loans at bank paid</dt>\n",
       "\t\t<dd>0.00474814027210446</dd>\n",
       "\t<dt>credit_history.critical account - other non-bank loans</dt>\n",
       "\t\t<dd>0.0233886633082943</dd>\n",
       "\t<dt>credit_history.current loans paid</dt>\n",
       "\t\t<dd>-0.0757636814177663</dd>\n",
       "\t<dt>credit_history.no credit - paid</dt>\n",
       "\t\t<dd>0.0182902559909015</dd>\n",
       "\t<dt>credit_history.past payment delays</dt>\n",
       "\t\t<dd>0.0293366218464661</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[checking\\textbackslash{}\\_account\\textbackslash{}\\_status.< 0 DM] 0.00418242624022571\n",
       "\\item[checking\\textbackslash{}\\_account\\textbackslash{}\\_status.> 200 DM or salary assignment] -0.0170404247032728\n",
       "\\item[checking\\textbackslash{}\\_account\\textbackslash{}\\_status.0 - 200 DM] 0.0130986240491562\n",
       "\\item[checking\\textbackslash{}\\_account\\textbackslash{}\\_status.none] -0.000240625586109156\n",
       "\\item[loan\\textbackslash{}\\_duration\\textbackslash{}\\_mo] 0.591263628398861\n",
       "\\item[credit\\textbackslash{}\\_history.all loans at bank paid] 0.00474814027210446\n",
       "\\item[credit\\textbackslash{}\\_history.critical account - other non-bank loans] 0.0233886633082943\n",
       "\\item[credit\\textbackslash{}\\_history.current loans paid] -0.0757636814177663\n",
       "\\item[credit\\textbackslash{}\\_history.no credit - paid] 0.0182902559909015\n",
       "\\item[credit\\textbackslash{}\\_history.past payment delays] 0.0293366218464661\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "checking_account_status.&amp;lt; 0 DM\n",
       ":   0.00418242624022571checking_account_status.&amp;gt; 200 DM or salary assignment\n",
       ":   -0.0170404247032728checking_account_status.0 - 200 DM\n",
       ":   0.0130986240491562checking_account_status.none\n",
       ":   -0.000240625586109156loan_duration_mo\n",
       ":   0.591263628398861credit_history.all loans at bank paid\n",
       ":   0.00474814027210446credit_history.critical account - other non-bank loans\n",
       ":   0.0233886633082943credit_history.current loans paid\n",
       ":   -0.0757636814177663credit_history.no credit - paid\n",
       ":   0.0182902559909015credit_history.past payment delays\n",
       ":   0.0293366218464661\n",
       "\n"
      ],
      "text/plain": [
       "                        checking_account_status.< 0 DM \n",
       "                                          0.0041824262 \n",
       " checking_account_status.> 200 DM or salary assignment \n",
       "                                         -0.0170404247 \n",
       "                    checking_account_status.0 - 200 DM \n",
       "                                          0.0130986240 \n",
       "                          checking_account_status.none \n",
       "                                         -0.0002406256 \n",
       "                                      loan_duration_mo \n",
       "                                          0.5912636284 \n",
       "                 credit_history.all loans at bank paid \n",
       "                                          0.0047481403 \n",
       "credit_history.critical account - other non-bank loans \n",
       "                                          0.0233886633 \n",
       "                     credit_history.current loans paid \n",
       "                                         -0.0757636814 \n",
       "                       credit_history.no credit - paid \n",
       "                                          0.0182902560 \n",
       "                    credit_history.past payment delays \n",
       "                                          0.0293366218 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Compute first 10 PCA components \n",
    "pca_credit_10 = prcomp(training, rank = 10)\n",
    "\n",
    "## Scale the eigenvalues\n",
    "var_exp_10 = pca_credit_10$sdev**2/sum(pca_credit_10$sdev**2)\n",
    "Nrow = nrow(pca_credit_10$rotation)\n",
    "Ncol = ncol(pca_credit_10$rotation)\n",
    "scaled_pca_10 = data.frame(matrix(rep(0, Nrow * Ncol), nrow = Nrow, ncol = Ncol))\n",
    "\n",
    "## Scale the rotations\n",
    "for(i in 1:Nrow){\n",
    "    scaled_pca_10[i,] = pca_credit_10$rotation[i,] * var_exp_10[1:Ncol]\n",
    "}\n",
    "\n",
    "## Print the dimensions of the scalled rotations and the first component\n",
    "dim(scaled_pca_10)\n",
    "pca_credit_10$rotation[1:10,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaled rotation matrix has dimensions of 61 rows and 10 columns. You can see the first 10 elements of the first rotation. Multiplying these numbers by the features rotate each row (case) to the new coordinate system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and evaluate a logistic regression model\n",
    "\n",
    "Next, you will compute and evaluate a logistic regression model using the features transformed by the first 10 principal components. The code in the cell below performs the matrix multiplication between the features and on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>700</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 700\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 700\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 700  61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_10 = training %*% as.matrix(scaled_pca_10)\n",
    "dim(training_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 10 transformed features. \n",
    "\n",
    "Now you will now construct and evaluate a logistic regression model by executing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>1.63246994242404</dd>\n",
       "\t<dt>X1</dt>\n",
       "\t\t<dd>-2.06599174666822</dd>\n",
       "\t<dt>X2</dt>\n",
       "\t\t<dd>-2.70312431204796</dd>\n",
       "\t<dt>X3</dt>\n",
       "\t\t<dd>-4.58110395930424</dd>\n",
       "\t<dt>X4</dt>\n",
       "\t\t<dd>6.50744833839239</dd>\n",
       "\t<dt>X5</dt>\n",
       "\t\t<dd>12.16186770534</dd>\n",
       "\t<dt>X6</dt>\n",
       "\t\t<dd>-24.1136809722411</dd>\n",
       "\t<dt>X7</dt>\n",
       "\t\t<dd>26.9863920079104</dd>\n",
       "\t<dt>X8</dt>\n",
       "\t\t<dd>9.81670671702304</dd>\n",
       "\t<dt>X9</dt>\n",
       "\t\t<dd>-1.66255383944179</dd>\n",
       "\t<dt>X10</dt>\n",
       "\t\t<dd>-14.4728464165616</dd>\n",
       "\t<dt>X11</dt>\n",
       "\t\t<dd>25.6719956756843</dd>\n",
       "\t<dt>X12</dt>\n",
       "\t\t<dd>21.0768348509067</dd>\n",
       "\t<dt>X13</dt>\n",
       "\t\t<dd>24.2732738807952</dd>\n",
       "\t<dt>X14</dt>\n",
       "\t\t<dd>-11.5897984788212</dd>\n",
       "\t<dt>X15</dt>\n",
       "\t\t<dd>0.156223143229566</dd>\n",
       "\t<dt>X16</dt>\n",
       "\t\t<dd>-5.4541500689974</dd>\n",
       "\t<dt>X17</dt>\n",
       "\t\t<dd>-23.5935517532286</dd>\n",
       "\t<dt>X18</dt>\n",
       "\t\t<dd>1.00475917002997</dd>\n",
       "\t<dt>X19</dt>\n",
       "\t\t<dd>-0.350583683968702</dd>\n",
       "\t<dt>X20</dt>\n",
       "\t\t<dd>-30.8402050927164</dd>\n",
       "\t<dt>X21</dt>\n",
       "\t\t<dd>38.1167065729071</dd>\n",
       "\t<dt>X22</dt>\n",
       "\t\t<dd>-7.56157638156674</dd>\n",
       "\t<dt>X23</dt>\n",
       "\t\t<dd>2.92836558502648</dd>\n",
       "\t<dt>X24</dt>\n",
       "\t\t<dd>-17.82331668797</dd>\n",
       "\t<dt>X25</dt>\n",
       "\t\t<dd>10.5407172720413</dd>\n",
       "\t<dt>X26</dt>\n",
       "\t\t<dd>44.2227815217356</dd>\n",
       "\t<dt>X27</dt>\n",
       "\t\t<dd>-7.87263214624975</dd>\n",
       "\t<dt>X28</dt>\n",
       "\t\t<dd>30.0615594941916</dd>\n",
       "\t<dt>X29</dt>\n",
       "\t\t<dd>45.5329259424589</dd>\n",
       "\t<dt>X30</dt>\n",
       "\t\t<dd>86.9515279987292</dd>\n",
       "\t<dt>X31</dt>\n",
       "\t\t<dd>70.5349649233861</dd>\n",
       "\t<dt>X32</dt>\n",
       "\t\t<dd>-144.20614723255</dd>\n",
       "\t<dt>X33</dt>\n",
       "\t\t<dd>13.555136851971</dd>\n",
       "\t<dt>X34</dt>\n",
       "\t\t<dd>100.719068908128</dd>\n",
       "\t<dt>X35</dt>\n",
       "\t\t<dd>117.166068708167</dd>\n",
       "\t<dt>X36</dt>\n",
       "\t\t<dd>27.1015228050831</dd>\n",
       "\t<dt>X37</dt>\n",
       "\t\t<dd>-56.4379277233208</dd>\n",
       "\t<dt>X38</dt>\n",
       "\t\t<dd>184.558874875038</dd>\n",
       "\t<dt>X39</dt>\n",
       "\t\t<dd>57.9523095773846</dd>\n",
       "\t<dt>X40</dt>\n",
       "\t\t<dd>146.642478528018</dd>\n",
       "\t<dt>X41</dt>\n",
       "\t\t<dd>-240.700000195277</dd>\n",
       "\t<dt>X42</dt>\n",
       "\t\t<dd>-105.556915583442</dd>\n",
       "\t<dt>X43</dt>\n",
       "\t\t<dd>-27.0799740874605</dd>\n",
       "\t<dt>X44</dt>\n",
       "\t\t<dd>264.569988887443</dd>\n",
       "\t<dt>X45</dt>\n",
       "\t\t<dd>-267.195630656035</dd>\n",
       "\t<dt>X46</dt>\n",
       "\t\t<dd>1026.04146424159</dd>\n",
       "\t<dt>X47</dt>\n",
       "\t\t<dd>1267.28653194179</dd>\n",
       "\t<dt>X48</dt>\n",
       "\t\t<dd>-1008.52410555434</dd>\n",
       "\t<dt>X49</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X50</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X51</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X52</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X53</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X54</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X55</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X56</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X57</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X58</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X59</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X60</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X61</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 1.63246994242404\n",
       "\\item[X1] -2.06599174666822\n",
       "\\item[X2] -2.70312431204796\n",
       "\\item[X3] -4.58110395930424\n",
       "\\item[X4] 6.50744833839239\n",
       "\\item[X5] 12.16186770534\n",
       "\\item[X6] -24.1136809722411\n",
       "\\item[X7] 26.9863920079104\n",
       "\\item[X8] 9.81670671702304\n",
       "\\item[X9] -1.66255383944179\n",
       "\\item[X10] -14.4728464165616\n",
       "\\item[X11] 25.6719956756843\n",
       "\\item[X12] 21.0768348509067\n",
       "\\item[X13] 24.2732738807952\n",
       "\\item[X14] -11.5897984788212\n",
       "\\item[X15] 0.156223143229566\n",
       "\\item[X16] -5.4541500689974\n",
       "\\item[X17] -23.5935517532286\n",
       "\\item[X18] 1.00475917002997\n",
       "\\item[X19] -0.350583683968702\n",
       "\\item[X20] -30.8402050927164\n",
       "\\item[X21] 38.1167065729071\n",
       "\\item[X22] -7.56157638156674\n",
       "\\item[X23] 2.92836558502648\n",
       "\\item[X24] -17.82331668797\n",
       "\\item[X25] 10.5407172720413\n",
       "\\item[X26] 44.2227815217356\n",
       "\\item[X27] -7.87263214624975\n",
       "\\item[X28] 30.0615594941916\n",
       "\\item[X29] 45.5329259424589\n",
       "\\item[X30] 86.9515279987292\n",
       "\\item[X31] 70.5349649233861\n",
       "\\item[X32] -144.20614723255\n",
       "\\item[X33] 13.555136851971\n",
       "\\item[X34] 100.719068908128\n",
       "\\item[X35] 117.166068708167\n",
       "\\item[X36] 27.1015228050831\n",
       "\\item[X37] -56.4379277233208\n",
       "\\item[X38] 184.558874875038\n",
       "\\item[X39] 57.9523095773846\n",
       "\\item[X40] 146.642478528018\n",
       "\\item[X41] -240.700000195277\n",
       "\\item[X42] -105.556915583442\n",
       "\\item[X43] -27.0799740874605\n",
       "\\item[X44] 264.569988887443\n",
       "\\item[X45] -267.195630656035\n",
       "\\item[X46] 1026.04146424159\n",
       "\\item[X47] 1267.28653194179\n",
       "\\item[X48] -1008.52410555434\n",
       "\\item[X49] NA\n",
       "\\item[X50] NA\n",
       "\\item[X51] NA\n",
       "\\item[X52] NA\n",
       "\\item[X53] NA\n",
       "\\item[X54] NA\n",
       "\\item[X55] NA\n",
       "\\item[X56] NA\n",
       "\\item[X57] NA\n",
       "\\item[X58] NA\n",
       "\\item[X59] NA\n",
       "\\item[X60] NA\n",
       "\\item[X61] NA\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   1.63246994242404X1\n",
       ":   -2.06599174666822X2\n",
       ":   -2.70312431204796X3\n",
       ":   -4.58110395930424X4\n",
       ":   6.50744833839239X5\n",
       ":   12.16186770534X6\n",
       ":   -24.1136809722411X7\n",
       ":   26.9863920079104X8\n",
       ":   9.81670671702304X9\n",
       ":   -1.66255383944179X10\n",
       ":   -14.4728464165616X11\n",
       ":   25.6719956756843X12\n",
       ":   21.0768348509067X13\n",
       ":   24.2732738807952X14\n",
       ":   -11.5897984788212X15\n",
       ":   0.156223143229566X16\n",
       ":   -5.4541500689974X17\n",
       ":   -23.5935517532286X18\n",
       ":   1.00475917002997X19\n",
       ":   -0.350583683968702X20\n",
       ":   -30.8402050927164X21\n",
       ":   38.1167065729071X22\n",
       ":   -7.56157638156674X23\n",
       ":   2.92836558502648X24\n",
       ":   -17.82331668797X25\n",
       ":   10.5407172720413X26\n",
       ":   44.2227815217356X27\n",
       ":   -7.87263214624975X28\n",
       ":   30.0615594941916X29\n",
       ":   45.5329259424589X30\n",
       ":   86.9515279987292X31\n",
       ":   70.5349649233861X32\n",
       ":   -144.20614723255X33\n",
       ":   13.555136851971X34\n",
       ":   100.719068908128X35\n",
       ":   117.166068708167X36\n",
       ":   27.1015228050831X37\n",
       ":   -56.4379277233208X38\n",
       ":   184.558874875038X39\n",
       ":   57.9523095773846X40\n",
       ":   146.642478528018X41\n",
       ":   -240.700000195277X42\n",
       ":   -105.556915583442X43\n",
       ":   -27.0799740874605X44\n",
       ":   264.569988887443X45\n",
       ":   -267.195630656035X46\n",
       ":   1026.04146424159X47\n",
       ":   1267.28653194179X48\n",
       ":   -1008.52410555434X49\n",
       ":   NAX50\n",
       ":   NAX51\n",
       ":   NAX52\n",
       ":   NAX53\n",
       ":   NAX54\n",
       ":   NAX55\n",
       ":   NAX56\n",
       ":   NAX57\n",
       ":   NAX58\n",
       ":   NAX59\n",
       ":   NAX60\n",
       ":   NAX61\n",
       ":   NA\n",
       "\n"
      ],
      "text/plain": [
       "  (Intercept)            X1            X2            X3            X4 \n",
       "    1.6324699    -2.0659917    -2.7031243    -4.5811040     6.5074483 \n",
       "           X5            X6            X7            X8            X9 \n",
       "   12.1618677   -24.1136810    26.9863920     9.8167067    -1.6625538 \n",
       "          X10           X11           X12           X13           X14 \n",
       "  -14.4728464    25.6719957    21.0768349    24.2732739   -11.5897985 \n",
       "          X15           X16           X17           X18           X19 \n",
       "    0.1562231    -5.4541501   -23.5935518     1.0047592    -0.3505837 \n",
       "          X20           X21           X22           X23           X24 \n",
       "  -30.8402051    38.1167066    -7.5615764     2.9283656   -17.8233167 \n",
       "          X25           X26           X27           X28           X29 \n",
       "   10.5407173    44.2227815    -7.8726321    30.0615595    45.5329259 \n",
       "          X30           X31           X32           X33           X34 \n",
       "   86.9515280    70.5349649  -144.2061472    13.5551369   100.7190689 \n",
       "          X35           X36           X37           X38           X39 \n",
       "  117.1660687    27.1015228   -56.4379277   184.5588749    57.9523096 \n",
       "          X40           X41           X42           X43           X44 \n",
       "  146.6424785  -240.7000002  -105.5569156   -27.0799741   264.5699889 \n",
       "          X45           X46           X47           X48           X49 \n",
       " -267.1956307  1026.0414642  1267.2865319 -1008.5241056            NA \n",
       "          X50           X51           X52           X53           X54 \n",
       "           NA            NA            NA            NA            NA \n",
       "          X55           X56           X57           X58           X59 \n",
       "           NA            NA            NA            NA            NA \n",
       "          X60           X61 \n",
       "           NA            NA "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Construct a data frame with the transformed features and label\n",
    "training_10 = data.frame(training_10)\n",
    "training_10[,'bad_credit'] = training_label\n",
    "\n",
    "## Create a weight vector for the training cases.\n",
    "weights = ifelse(training_10$bad_credit == 'bad', 0.66, 0.34)\n",
    "\n",
    "## Define and fit the logistic regression model\n",
    "set.seed(5566)\n",
    "logistic_mod_10 = glm(bad_credit ~ ., data = training_10, \n",
    "                      weights = weights, family = quasibinomial)\n",
    "logistic_mod_10$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are now 10 regression coefficients, one for each component plus an intercept. This number is in contrast to the 61 features in the dummy variable array. \n",
    "\n",
    "In order to test the model, the test feature array must also be transformed. Execute the code in the cell below to apply the PCA transformation to the test features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>300</li>\n",
       "\t<li>62</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 300\n",
       "\\item 62\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 300\n",
       "2. 62\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 300  62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_10 = test %*% as.matrix(scaled_pca_10)\n",
    "test_10 = data.frame(test_10)\n",
    "test_10[,'bad_credit'] = test_label\n",
    "dim(test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to score the model using the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>bad_credit</th><th scope=col>probs</th><th scope=col>score</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>bad      </td><td>0.2558205</td><td>bad      </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>good     </td><td>0.6838830</td><td>good     </td></tr>\n",
       "\t<tr><th scope=row>17</th><td>good     </td><td>0.9438269</td><td>good     </td></tr>\n",
       "\t<tr><th scope=row>21</th><td>good     </td><td>0.8328900</td><td>good     </td></tr>\n",
       "\t<tr><th scope=row>24</th><td>good     </td><td>0.8836840</td><td>good     </td></tr>\n",
       "\t<tr><th scope=row>27</th><td>good     </td><td>0.7313613</td><td>good     </td></tr>\n",
       "\t<tr><th scope=row>28</th><td>good     </td><td>0.6787652</td><td>good     </td></tr>\n",
       "\t<tr><th scope=row>30</th><td>bad      </td><td>0.2475953</td><td>bad      </td></tr>\n",
       "\t<tr><th scope=row>32</th><td>good     </td><td>0.2717953</td><td>bad      </td></tr>\n",
       "\t<tr><th scope=row>33</th><td>good     </td><td>0.5048484</td><td>good     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       "  & bad\\_credit & probs & score\\\\\n",
       "\\hline\n",
       "\t2 & bad       & 0.2558205 & bad      \\\\\n",
       "\t6 & good      & 0.6838830 & good     \\\\\n",
       "\t17 & good      & 0.9438269 & good     \\\\\n",
       "\t21 & good      & 0.8328900 & good     \\\\\n",
       "\t24 & good      & 0.8836840 & good     \\\\\n",
       "\t27 & good      & 0.7313613 & good     \\\\\n",
       "\t28 & good      & 0.6787652 & good     \\\\\n",
       "\t30 & bad       & 0.2475953 & bad      \\\\\n",
       "\t32 & good      & 0.2717953 & bad      \\\\\n",
       "\t33 & good      & 0.5048484 & good     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | bad_credit | probs | score | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 2 | bad       | 0.2558205 | bad       | \n",
       "| 6 | good      | 0.6838830 | good      | \n",
       "| 17 | good      | 0.9438269 | good      | \n",
       "| 21 | good      | 0.8328900 | good      | \n",
       "| 24 | good      | 0.8836840 | good      | \n",
       "| 27 | good      | 0.7313613 | good      | \n",
       "| 28 | good      | 0.6787652 | good      | \n",
       "| 30 | bad       | 0.2475953 | bad       | \n",
       "| 32 | good      | 0.2717953 | bad       | \n",
       "| 33 | good      | 0.5048484 | good      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   bad_credit probs     score\n",
       "2  bad        0.2558205 bad  \n",
       "6  good       0.6838830 good \n",
       "17 good       0.9438269 good \n",
       "21 good       0.8328900 good \n",
       "24 good       0.8836840 good \n",
       "27 good       0.7313613 good \n",
       "28 good       0.6787652 good \n",
       "30 bad        0.2475953 bad  \n",
       "32 good       0.2717953 bad  \n",
       "33 good       0.5048484 good "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_model = function(df, threshold){\n",
    "    df$score = ifelse(df$probs < threshold, 'bad', 'good')\n",
    "    df\n",
    "}\n",
    "\n",
    "test_10$probs = predict(logistic_mod_10, newdata = test_10, type = 'response')\n",
    "test_10 = score_model(test_10, 0.5)\n",
    "test_10[1:10, c('bad_credit','probs', 'score')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code in the cell below to evaluate the 10 PCA component logistic regression model.\n",
    "\n",
    "Then, answer **Question 1** on the course page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Negative Positive\n",
      "Actual Negative      171       39\n",
      "Actual Positive       28       62\n",
      "\n",
      "accuracy  = 0.777 \n",
      "precision = 0.614 \n",
      "recall    = 0.689 \n",
      "F1        = 0.649 \n",
      "AUC       = 0.823 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAMAAACJuGjuAAAAM1BMVEUAAABNTU1oaGh8fHyM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\n0FcAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logistic.eval <- function(df){ \n",
    "  # First step is to find the TP, FP, TN, FN cases\n",
    "  df$conf = ifelse(df$bad_credit == 'bad' & df$score == 'bad', 'TP',\n",
    "                    ifelse(df$bad_credit == 'bad' & df$score == 'good', 'FN',\n",
    "                           ifelse(df$bad_credit == 'good' & df$score == 'good', 'TN', 'FP')))\n",
    "\n",
    "  # Elements of the confusion matrix\n",
    "  TP = length(df[df$conf == 'TP', 'conf'])\n",
    "  FP = length(df[df$conf == 'FP', 'conf'])\n",
    "  TN = length(df[df$conf == 'TN', 'conf'])\n",
    "  FN = length(df[df$conf == 'FN', 'conf'])\n",
    "  \n",
    "  ## Confusion matrix as data frame\n",
    "  out = data.frame(Negative = c(TN, FN), Positive = c(FP, TP))\n",
    "  row.names(out) = c('Actual Negative', 'Actual Positive')\n",
    "  print(out)  \n",
    "  \n",
    "  # Compute and print metrics\n",
    "  P = TP/(TP + FP)\n",
    "  R = TP/(TP + FN)  \n",
    "  F1 = 2*P*R/(P+R)  \n",
    "  cat('\\n')\n",
    "  cat(paste('accuracy  =', as.character(round((TP + TN)/(TP + TN + FP + FN), 3)), '\\n'))      \n",
    "  cat(paste('precision =', as.character(round(P, 3)), '\\n'))     \n",
    "  cat(paste('recall    =', as.character(round(R, 3)), '\\n'))\n",
    "  cat(paste('F1        =', as.character(round(F1,3)),'\\n'))\n",
    "    \n",
    "  roc_obj <- roc(df$bad_credit, df$probs)\n",
    "  cat(paste('AUC       =', as.character(round(auc(roc_obj),3)),'\\n'))\n",
    "}\n",
    "\n",
    "ROC_AUC = function(df){\n",
    "    options(repr.plot.width=5, repr.plot.height=5)\n",
    "    pred_obj = prediction(df$probs, df$bad_credit)\n",
    "    perf_obj <- performance(pred_obj, measure = \"tpr\", x.measure = \"fpr\")\n",
    "    AUC = performance(pred_obj,\"auc\")@y.values[[1]] # Access the AUC from the slot of the S4 object\n",
    "    plot(perf_obj)\n",
    "    abline(a=0, b= 1, col = 'red')\n",
    "    text(0.8, 0.2, paste('AUC = ', as.character(round(AUC, 3))))\n",
    "}\n",
    "\n",
    "logistic.eval(test_10)\n",
    "ROC_AUC(test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are reasonably good. Recall, accuracy and AUC have reasonable values, however precision and F1 are low. Is it possible that more PCA components are required to achieve a good model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more components to the model\n",
    "\n",
    "Now you will compute and evaluate a logistic regression model using the first 20 principal components. You will compare this model to the one created with 10 principal components. \n",
    "\n",
    "Execute the code below to transform the training features using the first 20 principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"In prcomp.default(training, rank = 20) :\n",
      " extra argument 'rank' will be disregarded\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>61</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 61\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 61\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 61 61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Compute first 10 PCA components \n",
    "pca_credit_20 = prcomp(training, rank = 20)\n",
    "\n",
    "## Scale the eigenvalues\n",
    "var_exp_20 = pca_credit_20$sdev**2/sum(pca_credit_20$sdev**2)\n",
    "Nrow = nrow(pca_credit_20$rotation)\n",
    "Ncol = ncol(pca_credit_20$rotation)\n",
    "scaled_pca_20 = data.frame(matrix(rep(0, Nrow * Ncol), nrow = Nrow, ncol = Ncol))\n",
    "\n",
    "## Scale the rotations\n",
    "for(i in 1:Nrow){\n",
    "    scaled_pca_20[i,] = pca_credit_20$rotation[i,] * var_exp_20[1:Ncol]\n",
    "}\n",
    "\n",
    "## Print the dimensions of the scalled rotations and the first component\n",
    "dim(scaled_pca_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 20 components in the PCA model. \n",
    "\n",
    "The code in the cell below computes the transformed feature set and creates a logistic regression model from this feature set. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>1.63246994242404</dd>\n",
       "\t<dt>X1</dt>\n",
       "\t\t<dd>-2.06599174666822</dd>\n",
       "\t<dt>X2</dt>\n",
       "\t\t<dd>-2.70312431204796</dd>\n",
       "\t<dt>X3</dt>\n",
       "\t\t<dd>-4.58110395930424</dd>\n",
       "\t<dt>X4</dt>\n",
       "\t\t<dd>6.50744833839239</dd>\n",
       "\t<dt>X5</dt>\n",
       "\t\t<dd>12.16186770534</dd>\n",
       "\t<dt>X6</dt>\n",
       "\t\t<dd>-24.1136809722411</dd>\n",
       "\t<dt>X7</dt>\n",
       "\t\t<dd>26.9863920079104</dd>\n",
       "\t<dt>X8</dt>\n",
       "\t\t<dd>9.81670671702304</dd>\n",
       "\t<dt>X9</dt>\n",
       "\t\t<dd>-1.66255383944179</dd>\n",
       "\t<dt>X10</dt>\n",
       "\t\t<dd>-14.4728464165616</dd>\n",
       "\t<dt>X11</dt>\n",
       "\t\t<dd>25.6719956756843</dd>\n",
       "\t<dt>X12</dt>\n",
       "\t\t<dd>21.0768348509067</dd>\n",
       "\t<dt>X13</dt>\n",
       "\t\t<dd>24.2732738807952</dd>\n",
       "\t<dt>X14</dt>\n",
       "\t\t<dd>-11.5897984788212</dd>\n",
       "\t<dt>X15</dt>\n",
       "\t\t<dd>0.156223143229566</dd>\n",
       "\t<dt>X16</dt>\n",
       "\t\t<dd>-5.4541500689974</dd>\n",
       "\t<dt>X17</dt>\n",
       "\t\t<dd>-23.5935517532286</dd>\n",
       "\t<dt>X18</dt>\n",
       "\t\t<dd>1.00475917002997</dd>\n",
       "\t<dt>X19</dt>\n",
       "\t\t<dd>-0.350583683968702</dd>\n",
       "\t<dt>X20</dt>\n",
       "\t\t<dd>-30.8402050927164</dd>\n",
       "\t<dt>X21</dt>\n",
       "\t\t<dd>38.1167065729071</dd>\n",
       "\t<dt>X22</dt>\n",
       "\t\t<dd>-7.56157638156674</dd>\n",
       "\t<dt>X23</dt>\n",
       "\t\t<dd>2.92836558502648</dd>\n",
       "\t<dt>X24</dt>\n",
       "\t\t<dd>-17.82331668797</dd>\n",
       "\t<dt>X25</dt>\n",
       "\t\t<dd>10.5407172720413</dd>\n",
       "\t<dt>X26</dt>\n",
       "\t\t<dd>44.2227815217356</dd>\n",
       "\t<dt>X27</dt>\n",
       "\t\t<dd>-7.87263214624975</dd>\n",
       "\t<dt>X28</dt>\n",
       "\t\t<dd>30.0615594941916</dd>\n",
       "\t<dt>X29</dt>\n",
       "\t\t<dd>45.5329259424589</dd>\n",
       "\t<dt>X30</dt>\n",
       "\t\t<dd>86.9515279987292</dd>\n",
       "\t<dt>X31</dt>\n",
       "\t\t<dd>70.5349649233861</dd>\n",
       "\t<dt>X32</dt>\n",
       "\t\t<dd>-144.20614723255</dd>\n",
       "\t<dt>X33</dt>\n",
       "\t\t<dd>13.555136851971</dd>\n",
       "\t<dt>X34</dt>\n",
       "\t\t<dd>100.719068908128</dd>\n",
       "\t<dt>X35</dt>\n",
       "\t\t<dd>117.166068708167</dd>\n",
       "\t<dt>X36</dt>\n",
       "\t\t<dd>27.1015228050831</dd>\n",
       "\t<dt>X37</dt>\n",
       "\t\t<dd>-56.4379277233208</dd>\n",
       "\t<dt>X38</dt>\n",
       "\t\t<dd>184.558874875038</dd>\n",
       "\t<dt>X39</dt>\n",
       "\t\t<dd>57.9523095773846</dd>\n",
       "\t<dt>X40</dt>\n",
       "\t\t<dd>146.642478528018</dd>\n",
       "\t<dt>X41</dt>\n",
       "\t\t<dd>-240.700000195277</dd>\n",
       "\t<dt>X42</dt>\n",
       "\t\t<dd>-105.556915583442</dd>\n",
       "\t<dt>X43</dt>\n",
       "\t\t<dd>-27.0799740874605</dd>\n",
       "\t<dt>X44</dt>\n",
       "\t\t<dd>264.569988887443</dd>\n",
       "\t<dt>X45</dt>\n",
       "\t\t<dd>-267.195630656035</dd>\n",
       "\t<dt>X46</dt>\n",
       "\t\t<dd>1026.04146424159</dd>\n",
       "\t<dt>X47</dt>\n",
       "\t\t<dd>1267.28653194179</dd>\n",
       "\t<dt>X48</dt>\n",
       "\t\t<dd>-1008.52410555434</dd>\n",
       "\t<dt>X49</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X50</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X51</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X52</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X53</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X54</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X55</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X56</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X57</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X58</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X59</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X60</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "\t<dt>X61</dt>\n",
       "\t\t<dd>NA</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 1.63246994242404\n",
       "\\item[X1] -2.06599174666822\n",
       "\\item[X2] -2.70312431204796\n",
       "\\item[X3] -4.58110395930424\n",
       "\\item[X4] 6.50744833839239\n",
       "\\item[X5] 12.16186770534\n",
       "\\item[X6] -24.1136809722411\n",
       "\\item[X7] 26.9863920079104\n",
       "\\item[X8] 9.81670671702304\n",
       "\\item[X9] -1.66255383944179\n",
       "\\item[X10] -14.4728464165616\n",
       "\\item[X11] 25.6719956756843\n",
       "\\item[X12] 21.0768348509067\n",
       "\\item[X13] 24.2732738807952\n",
       "\\item[X14] -11.5897984788212\n",
       "\\item[X15] 0.156223143229566\n",
       "\\item[X16] -5.4541500689974\n",
       "\\item[X17] -23.5935517532286\n",
       "\\item[X18] 1.00475917002997\n",
       "\\item[X19] -0.350583683968702\n",
       "\\item[X20] -30.8402050927164\n",
       "\\item[X21] 38.1167065729071\n",
       "\\item[X22] -7.56157638156674\n",
       "\\item[X23] 2.92836558502648\n",
       "\\item[X24] -17.82331668797\n",
       "\\item[X25] 10.5407172720413\n",
       "\\item[X26] 44.2227815217356\n",
       "\\item[X27] -7.87263214624975\n",
       "\\item[X28] 30.0615594941916\n",
       "\\item[X29] 45.5329259424589\n",
       "\\item[X30] 86.9515279987292\n",
       "\\item[X31] 70.5349649233861\n",
       "\\item[X32] -144.20614723255\n",
       "\\item[X33] 13.555136851971\n",
       "\\item[X34] 100.719068908128\n",
       "\\item[X35] 117.166068708167\n",
       "\\item[X36] 27.1015228050831\n",
       "\\item[X37] -56.4379277233208\n",
       "\\item[X38] 184.558874875038\n",
       "\\item[X39] 57.9523095773846\n",
       "\\item[X40] 146.642478528018\n",
       "\\item[X41] -240.700000195277\n",
       "\\item[X42] -105.556915583442\n",
       "\\item[X43] -27.0799740874605\n",
       "\\item[X44] 264.569988887443\n",
       "\\item[X45] -267.195630656035\n",
       "\\item[X46] 1026.04146424159\n",
       "\\item[X47] 1267.28653194179\n",
       "\\item[X48] -1008.52410555434\n",
       "\\item[X49] NA\n",
       "\\item[X50] NA\n",
       "\\item[X51] NA\n",
       "\\item[X52] NA\n",
       "\\item[X53] NA\n",
       "\\item[X54] NA\n",
       "\\item[X55] NA\n",
       "\\item[X56] NA\n",
       "\\item[X57] NA\n",
       "\\item[X58] NA\n",
       "\\item[X59] NA\n",
       "\\item[X60] NA\n",
       "\\item[X61] NA\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   1.63246994242404X1\n",
       ":   -2.06599174666822X2\n",
       ":   -2.70312431204796X3\n",
       ":   -4.58110395930424X4\n",
       ":   6.50744833839239X5\n",
       ":   12.16186770534X6\n",
       ":   -24.1136809722411X7\n",
       ":   26.9863920079104X8\n",
       ":   9.81670671702304X9\n",
       ":   -1.66255383944179X10\n",
       ":   -14.4728464165616X11\n",
       ":   25.6719956756843X12\n",
       ":   21.0768348509067X13\n",
       ":   24.2732738807952X14\n",
       ":   -11.5897984788212X15\n",
       ":   0.156223143229566X16\n",
       ":   -5.4541500689974X17\n",
       ":   -23.5935517532286X18\n",
       ":   1.00475917002997X19\n",
       ":   -0.350583683968702X20\n",
       ":   -30.8402050927164X21\n",
       ":   38.1167065729071X22\n",
       ":   -7.56157638156674X23\n",
       ":   2.92836558502648X24\n",
       ":   -17.82331668797X25\n",
       ":   10.5407172720413X26\n",
       ":   44.2227815217356X27\n",
       ":   -7.87263214624975X28\n",
       ":   30.0615594941916X29\n",
       ":   45.5329259424589X30\n",
       ":   86.9515279987292X31\n",
       ":   70.5349649233861X32\n",
       ":   -144.20614723255X33\n",
       ":   13.555136851971X34\n",
       ":   100.719068908128X35\n",
       ":   117.166068708167X36\n",
       ":   27.1015228050831X37\n",
       ":   -56.4379277233208X38\n",
       ":   184.558874875038X39\n",
       ":   57.9523095773846X40\n",
       ":   146.642478528018X41\n",
       ":   -240.700000195277X42\n",
       ":   -105.556915583442X43\n",
       ":   -27.0799740874605X44\n",
       ":   264.569988887443X45\n",
       ":   -267.195630656035X46\n",
       ":   1026.04146424159X47\n",
       ":   1267.28653194179X48\n",
       ":   -1008.52410555434X49\n",
       ":   NAX50\n",
       ":   NAX51\n",
       ":   NAX52\n",
       ":   NAX53\n",
       ":   NAX54\n",
       ":   NAX55\n",
       ":   NAX56\n",
       ":   NAX57\n",
       ":   NAX58\n",
       ":   NAX59\n",
       ":   NAX60\n",
       ":   NAX61\n",
       ":   NA\n",
       "\n"
      ],
      "text/plain": [
       "  (Intercept)            X1            X2            X3            X4 \n",
       "    1.6324699    -2.0659917    -2.7031243    -4.5811040     6.5074483 \n",
       "           X5            X6            X7            X8            X9 \n",
       "   12.1618677   -24.1136810    26.9863920     9.8167067    -1.6625538 \n",
       "          X10           X11           X12           X13           X14 \n",
       "  -14.4728464    25.6719957    21.0768349    24.2732739   -11.5897985 \n",
       "          X15           X16           X17           X18           X19 \n",
       "    0.1562231    -5.4541501   -23.5935518     1.0047592    -0.3505837 \n",
       "          X20           X21           X22           X23           X24 \n",
       "  -30.8402051    38.1167066    -7.5615764     2.9283656   -17.8233167 \n",
       "          X25           X26           X27           X28           X29 \n",
       "   10.5407173    44.2227815    -7.8726321    30.0615595    45.5329259 \n",
       "          X30           X31           X32           X33           X34 \n",
       "   86.9515280    70.5349649  -144.2061472    13.5551369   100.7190689 \n",
       "          X35           X36           X37           X38           X39 \n",
       "  117.1660687    27.1015228   -56.4379277   184.5588749    57.9523096 \n",
       "          X40           X41           X42           X43           X44 \n",
       "  146.6424785  -240.7000002  -105.5569156   -27.0799741   264.5699889 \n",
       "          X45           X46           X47           X48           X49 \n",
       " -267.1956307  1026.0414642  1267.2865319 -1008.5241056            NA \n",
       "          X50           X51           X52           X53           X54 \n",
       "           NA            NA            NA            NA            NA \n",
       "          X55           X56           X57           X58           X59 \n",
       "           NA            NA            NA            NA            NA \n",
       "          X60           X61 \n",
       "           NA            NA "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Construct a data frame with the transformed features and label\n",
    "training_20 = training %*% as.matrix(scaled_pca_20)\n",
    "training_20 = data.frame(training_20)\n",
    "training_20[,'bad_credit'] = training_label\n",
    "\n",
    "weights = ifelse(training_20$bad_credit == 'bad', 0.66, 0.34)\n",
    "\n",
    "## Define and fit the logistic regression model\n",
    "set.seed(5566)\n",
    "logistic_mod_20 = glm(bad_credit ~ ., data = training_20, \n",
    "                      weights = weights, family = quasibinomial)\n",
    "logistic_mod_20$coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below scores the logistic regression model and displays performance metrics, the ROC curve, and the AUC. Execute this code and examine the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in predict.lm(object, newdata, se.fit, scale = 1, type = ifelse(type == :\n",
      "\"prediction from a rank-deficient fit may be misleading\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Negative Positive\n",
      "Actual Negative      171       39\n",
      "Actual Positive       28       62\n",
      "\n",
      "accuracy  = 0.777 \n",
      "precision = 0.614 \n",
      "recall    = 0.689 \n",
      "F1        = 0.649 \n",
      "AUC       = 0.823 \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAMAAACJuGjuAAAAM1BMVEUAAABNTU1oaGh8fHyM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\n0FcAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Create the transformed test dataset\n",
    "test_20 = test %*% as.matrix(scaled_pca_20)\n",
    "test_20 = data.frame(test_20)\n",
    "test_20[,'bad_credit'] = test_label\n",
    "\n",
    "## Score the model\n",
    "test_20$probs = predict(logistic_mod_20, newdata = test_20, type = 'response')\n",
    "test_20 = score_model(test_20, 0.5)\n",
    "\n",
    "## Evaluate the model\n",
    "logistic.eval(test_20)\n",
    "ROC_AUC(test_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics for the 20 component model are nearly the same as for the 10 component model. It appears that 10 components is enough to represent the information in the feature set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you have applied principal component analysis to dimensionality reduction for supervised machine learning. The first components computed contain most of the available information. When faced with large number of features, PCA is an effective way to make supervised machine learning models tractable. \n",
    "\n",
    "Specifically in this lab you have:\n",
    "1. Computed PCA models with different numbers of components.\n",
    "2. Compared logistic regression models with different numbers of components. In this case, using 10 components produced a good model. Extending this to 20 components gained little if anything. In summary the dimensionality of the original 61 dummy variable array to just 10 components. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
